---
title: "Linguistic Functions"
author: "Tan Lian-Hui"
date: "2021/7/15"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE,comment = '#>',error=TRUE, results = 'hold', out.width='70%')
```

```{r load data}
library(rjson)
library(readxl)
library(dplyr)
library(rms)

json_list <- fromJSON(file="C:/Users/user/Desktop/University/Extra Studies & Others'/Classic Thesis/Linguistics/semantics/ABSA/Linguistic Function/cht0714_ctxdep.json")
seeds_loc <- "C:/Users/user/Desktop/University/Extra Studies & Others'/Classic Thesis/Linguistics/semantics/ABSA/Linguistic Function/seeds_(å®¢æœ)_1100223.xlsx"
predict_loc <- "C:/Users/user/Desktop/University/Extra Studies & Others'/Classic Thesis/Linguistics/semantics/ABSA/Linguistic Function/ctx_predict.xlsx"

df<-data.frame()
for (i in 1:582){
    isCorrect<-json_list[[i]]$isCorrect
    row_idx<-json_list[[i]]$row_idx
    text<-json_list[[i]]$text
    token_dep<-json_list[[i]]$token_dep%>%
        unlist() %>%
        data.frame() %>%
        mutate(rn = ceiling(row_number() / 5)) %>%
        group_by(rn) %>%
        summarise(vlist = paste0(., collapse = "/")) %>%
        ungroup() %>%
        select(vlist) %>%
        t() %>%
        paste(collapse = "\u3000")

    row<-cbind(isCorrect, row_idx, text, token_dep)
    df<-rbind(df, row)
}

df_error<-df%>%filter(isCorrect==0)

read_excel_allsheets <- function(filename, tibble = FALSE) {
    sheets <- readxl::excel_sheets(filename)
    x <- lapply(sheets, function(X) readxl::read_excel(filename, sheet = X))
    if(!tibble) x <- lapply(x, as.data.frame)
    names(x) <- sheets
    x
}

seeds<-read_excel_allsheets(seeds_loc)
predict<-read_excel_allsheets(predict_loc)

predict_error<-predict$error %>% 
    as.data.frame() %>%
    filter(is.na(...7)) %>%
    select(contexts, notes_2)
```

# Data Manipulation
```{r entity counts}
# collect entities in `seeds` into `entities`
entities<-seeds$`seeds (å®¢æœ)0223`[2:7,3:25]%>%as_tibble()

# `splitslash` function simplifies the codes in `ent_num` below
splitslash<-function(x){
    s<-strsplit(x, split="/")%>%unlist()
    return(s[1])
}
# `ent_num` function uses TFlist to collect entity counts, based on `strsplit` twice by "\u3000" and "/"
ent_num<-function(x){
    TFlist<-list()
    str<-strsplit(x, split = "\u3000") %>% unlist()
    wordlist<-lapply(str, splitslash) %>% unlist()
    for (i in wordlist){
        TFlist<-append(TFlist, (any(entities==i, na.rm = TRUE)))
    }
    return(TFlist%>%unlist()%>%sum())
}
# `all_table` combines two tables for future comparisons
all_table<-left_join(df, predict_error, by=c("text"="contexts"))%>%
    rowwise()%>%
    mutate(entity_count = ent_num(token_dep))
```

```{r sentence length}
all_table<-all_table%>%mutate(word_count = nchar(text))
```

```{r longer than 43}
all_table<-all_table%>%
    mutate(above43 = if_else(condition = as.numeric(word_count)>43, 
                                     true = TRUE, false = FALSE))
```

```{r rhetorical question}
findqs<-function(x){
    return(grepl("rhetorical", x))
}
all_table<-all_table%>%
    mutate(ifQuestion = findqs(notes_2))
# flaw: cannot see unannotated predictions that might be either correct or wrong
```

```{r sign counts}
findsign<-function(x){
    return(grepl("[>=<^â¤ï¸ðŸ¤”ðŸ¤”ðŸ¤£ðŸ¥ºðŸ˜‚]", x))
}
all_table<-all_table%>%
    mutate(ifSign = findsign(text))
```

```{r adjective counts}
mostly_adj<-all_table$token_dep%>%
    as.character%>%
    strsplit("(\u3000)|(\", \")")%>%
    unlist()%>%
    as.data.frame()%>%
    filter(grepl("VA/[^(dep)]", x=.))

adj_num<-function(x){
    ls<-list()
    num<-x%>%
        strsplit("\u3000")%>%
        unlist()
    for (i in num){
        ls<-append(ls, (grepl("VA/[^(dep)]", i)))
    }
    return(ls%>%unlist()%>%sum())
}

all_table<-all_table%>%
    mutate(adj_count = adj_num(token_dep))
```

```{r sarcasm}
# (annotators' choice)
findsarcasm<-function(x){
    return(grepl("sarcasm", x))
}
all_table<-all_table%>%
    mutate(ifSarcasm = findsarcasm(notes_2))
# flaw: cannot see unannotated predictions that might be either correct or wrong
```

```{r conjugation counts}
conj_num<-function(x){
    conjunctions<-c("ä½†", "é™¤(äº†|å¤–|éž)?", "å»")
    TFlist<-list()
    str<-strsplit(x, split = "\u3000") %>% unlist()
    wordlist<-lapply(str, splitslash) %>% unlist()
    for (i in wordlist){
        TFlist<-append(TFlist, (any(conjunctions==i, na.rm = TRUE)))
    }
    return(TFlist%>%unlist()%>%sum())
}

all_table<-all_table%>%
    rowwise()%>%
    mutate(conj_count = conj_num(token_dep))
```

```{r negation counts}
neg_num<-function(x){
    negations<-c("ä¸", "æ²’æœ‰")
    TFlist<-list()
    str<-strsplit(x, split = "\u3000") %>% unlist()
    wordlist<-lapply(str, splitslash) %>% unlist()
    for (i in wordlist){
        TFlist<-append(TFlist, (any(negations==i, na.rm = TRUE)))
    }
    return(TFlist%>%unlist()%>%sum())
}

all_table<-all_table%>%
    rowwise()%>%
    mutate(neg_count = neg_num(token_dep))
```

# LRM result (one by one)
```{r factorize}
all_table$isCorrect <- factor(all_table$isCorrect)
all_table$entity_count <- factor(all_table$entity_count)
# all_table$word_count <- factor(all_table$word_count) 
all_table$ifQuestion <- factor(all_table$ifQuestion)
all_table$ifSign <- factor(all_table$ifSign)
all_table$above43 <- factor(all_table$above43)
all_table$adj_count <- factor(all_table$adj_count)
all_table$ifSarcasm <- factor(all_table$ifSarcasm)
all_table$conj_count <- factor(all_table$conj_count)
all_table$neg_count <- factor(all_table$neg_count)
```

```{r entity counts results}
result1 <- lrm(isCorrect ~ entity_count, 
              data = all_table, x = T, y = T)
result1
rms::vif(result1)
# Should print out:
# entity_count=1 entity_count=2 entity_count=3 entity_count=4 entity_count=5 
# 1.114813       1.088053       1.031909       1.007573       1.000011 
```

```{r sentence length results}
result2 <- lrm(isCorrect ~ word_count, 
              data = all_table, x = T, y = T)
result2
rms::vif(result2)
# Should print out:
# word_count=4   word_count=5   word_count=6   word_count=7   word_count=8   word_count=9   word_count=10  word_count=11  word_count=12  word_count=13 
# 3.599987       7019.653314    18758.490454   13801.969785   47512.004279   19500.034849   43470.570492   40006.782365   28352.607740   18758.490454 
# word_count=14  word_count=15  word_count=16  word_count=17  word_count=18  word_count=19  word_count=20  word_count=21  word_count=22  word_count=23 
# 32391.284615   13420.230319   67373.348168   12727.186861   19591.462318   26762.945420   26253.347874   34433.932246   19591.462318   25477.100791 
# word_count=24  word_count=25  word_count=26  word_count=27  word_count=28  word_count=29  word_count=30  word_count=31  word_count=32  word_count=33 
# 23471.848098   15524.932524   6246.838094    5999.165768    2.199996       5627.319592    22375.196153   16406.429626       1.599999    3762.010342 
# word_count=34  word_count=35  word_count=36  word_count=37  word_count=38  word_count=40  word_count=41  word_count=43  word_count=44  word_count=45 
# 12727.186861   5006.675466    1.399999       1.999997       3762.010342    3762.010342    7482.498227    5999.165768       1.277192       1.138596 
# word_count=46  word_count=47  word_count=49  word_count=50  word_count=51  word_count=54  word_count=55  word_count=56  word_count=57  word_count=59 
# 1.138596       1.399999       8959.347093    3762.010342    1.399999       1.200000       1.599999       1.399999       1.399999       1.138596 
# word_count=60  word_count=63  word_count=64  word_count=65  word_count=67  word_count=68  word_count=69  word_count=72  word_count=74  word_count=81 
# 1.200000       1.200000       1.399999       1.138596       1.200000       1.200000       3762.010342    3762.010342       1.138596       1.200000 
# word_count=82  word_count=85  word_count=91  word_count=96  word_count=101 word_count=104 word_count=106 word_count=122 word_count=129 word_count=162 
# 1.200000       1.200000       1.399999       1.200000       1.200000       1.200000       1.277192       1.200000       1.200000       1.200000 
# word_count=178 word_count=194 word_count=249 
# 1.200000       1.200000       1.200000 
```

```{r longer than 43 results}
result3 <- lrm(isCorrect ~ above43, 
              data = all_table, x = T, y = T)
result3
rms::vif(result3)
# above43=TRUE
# 1
```

```{r rhetorical question results}
result4 <- lrm(isCorrect ~ ifQuestion, 
              data = all_table, x = T, y = T)
result4
rms::vif(result4)
# ifQuestion=TRUE 
# 1 
```

```{r sign counts results}
result5 <- lrm(isCorrect ~ ifSign, 
              data = all_table, x = T, y = T)
result5
rms::vif(result5)
# ifSign=TRUE 
# 1
```

```{r adjective counts results}
result6 <- lrm(isCorrect ~ adj_count, 
              data = all_table, x = T, y = T)
result6
rms::vif(result6)
# adj_count=1 adj_count=2 adj_count=3 adj_count=5 
# 1.011716    1.011709    1.000006    1.000003 
```

```{r sarcasm results}
result7 <- lrm(isCorrect ~ ifSarcasm, 
              data = all_table, x = T, y = T)
result7
rms::vif(result7)
# ifSarcasm=TRUE 
# 1 
```

```{r conjugation counts results}
result8 <- lrm(isCorrect ~ conj_count, 
              data = all_table, x = T, y = T)
result8
rms::vif(result8)
# conj_count=1 conj_count=2 
# 1            1
```

```{r negation counts results}
result9 <- lrm(isCorrect ~ neg_count, 
               data = all_table, x = T, y = T)
result9
rms::vif(result9)
# neg_count=1 neg_count=2 neg_count=3 neg_count=4 
# 1.011437    1.011434    1.000003    1.000001 
```

# LRM result (as a whole)
```{r result}
result <- lrm(isCorrect ~ entity_count + ifQuestion + ifSign + above43 + adj_count + ifSarcasm + conj_count + neg_count, 
              data = all_table, x = T, y = T)
result
rms::vif(result)
# Should print out:
# entity_count=1  entity_count=2  entity_count=3 entity_count=4  entity_count=5 
# 1.136782        1.138409        1.215401       1.049619        1.000025 
# ifQuestion=TRUE 
# 1.000003 
# ifSign=TRUE
# 1.169715
# above43     
# 1.224590 
# adj_count=1     adj_count=2     adj_count=3     adj_count=5 
# 1.046447        1.043240        1.349316        1.000039 
# ifSarcasm=TRUE  
# 1.000007
# conj_count=1    conj_count=2 
# 1.032168        1.000002 
# neg_count=1     neg_count=2     neg_count=3     neg_count=4 
# 1.024981        1.212894        1.000075        1.349358 
```

If `word_count` is considered factors in the lrm, error message pops out: 
singular information matrix in lrm.fit (rank= 90 ).  Offending variable(s):neg_count=4 adj_count=5 above43 
Warning message:
In lrm(isCorrect ~ entity_count + word_count + ifQuestion + ifSign +  :
Unable to fit model using â€œlrm.fitâ€

```{r sentence count}
all_table <- all_table %>%
    mutate(sentence_count = text %>%
               strsplit(split = "( |ï¼Ÿ|ï¼|ï¼Œ|ã€‚)") %>%
               unlist() %>%
               length())
```

```{r sentence count result}
result10 <- lrm(isCorrect ~ sentence_count, 
              data = all_table, x = T, y = T)
result10
rms::vif(result10)
```

```{r sentence count as factor result}
fac10 <- factor(all_table$sentence_count)
result_fac10 <- lrm(isCorrect ~ fac10, 
              data = all_table, x = T, y = T)
result_fac10
rms::vif(result_fac10)
```
